Functional Requirements:
Service has to create unique short aliases url for long URLs
User has to redirect to original long url when they hit short url link 
User can form their own short url i.e. they can define their own unique token id 
Links will expire after a standard default timespan or User can specify the their own expiration time 
What is the length of the short url default token generated by service 
bit.ly, ow.ly, short.io → uses 7 or 8 has length of token 
What is the max length for the user provided token 
Will short url token can be alpha numeric
Error should be thrown saying that provided long url or destination url already taken. View the existing link 
Is Metrics needed
Metrics are important for analytics purpose like what urls have top most hits, from which region we are having most load etc. 
Non-Functional Requirements:
High Availability
Low Latency
Capacity Estimation (What limits system is able to handle) 
Capacity/Load Estimation:

write requests per month = 200 million
read: write = 200: 1
calculate write requests per seconds = 200 million / (30 days * 24 hrs * 60 min * 60 sec) = 200million /  2.6 million =  ~ 77 URL/sec
calculate read requests per seconds = 200 : 1 = 77 * 200  = 15 K /sec
Storage Estimation:
we save this data for 5 years, so calculate for 200 million requests per month, calculate for 5 years
200 million * 5 years * 12 months = 12000 million = 12 billion 
Assume each request is 500 bytes 
12 billion * 500  bytes= 6 TB 
Memory Estimation: This is for cache memory. Cache memory only we do for read per day
read requests per day = 15K * 24 *  3600 = 1.3 billion per day
80 to 20% rule = 0.2*1.3*500 = ~ 130 GB 
Data Model:

user_profile 
url_info 
user_profile
PK
id: serial
user_name: varchar
email:  varchar
creation_date: datetime
last_login: datetime
url_info
PK
id: serial
original_url: varchar
unique
token: varchar
FK
user_id: int
creation_date: datetime
expiration_date: datetime



API's: 

In the design of a TinyURL system, we will prioritize the development of APIs related to URL information over user profiles. These APIs play a crucial role in the functionality of the system.

createShortURL(String longURL, String customToken, DateTime expirationTime) → Response → Return shortURL or createShortURL(RequestBody) → Request Body contains longURL and metadata
getURL(String shortURL) → Response → Return LongURL
update(String shortURL, RequestBody(longurl, metadata)) → Return updated details of url 
delete(String shortURL) → Message confirms to delete it 
High Level Design:


LB
UI
ShortURL Generation Service
Key Generation Service
Read/Write
Redis Cache
Read/Write
Update Cache
MongoDB
Kafka
Apache Cassandra


Flow Explanation:

ShortURL Generation Service:
Write Case: ShortURL Generation Service accept the request for creation of short url and respond back with short url by saving data in mongo db 
Read Case without Cache: ShortURL Generation Service accept get request with short URL as input and respond back with original url by performing find operation on url_info based on token and respond back with original url for redirection
Read Case with Cache: Reading data from the database is consistently slower compared to reading from the cache. In order to reduce latency, we store data in the cache using a key-value pair (in our case token, {longURL, metadata}) during the initial retrieval, and for all subsequent identical requests, we retrieve the data from the cache rather than retrieving it from the database.
Key Generation Service: 
Generates keys a head of length 8 characters and stores in the Postgres DB. ShortURL Generation Service request batch of keys from Key Generation Service to pre-load this keys during the startup of service to get in used in generation of short url. Key Generation Service provides batch of keys and mark provided keys as used to ensure Key Generation Service not provided same batch in the next request. Service again pulls another batch of keys once all pre-loaded keys got used. If service dies before using all of preloaded keys, rest of unused keys get wasted which is acceptable as we have enough keys generated i.e. base62 with length of 8 characters is 37.4 trillion. 
If two services requesting keys at concurrently, we can solve this problem by having two tables one is used keys and other one is for unused keys.
Capturing Metrics:
ShortURL Generation Service asynchronously send message to Kafka to store in Cassandra for analytics purpose 
Justification:

Why we choose MongoDB: Since we are storing billion of rows and no need to use relation between objects we went to NoSQL. Mongo DB provides below things,
Document Indexing
Low Latency 
Auto Sharding to support Scalability
Replication 
Why we choose Redis: As it is distributed Cache and Lighting Fast Data Access
Lightning-Fast Data Access: Redis stores data entirely in memory, which means it can provide sub-millisecond response times. This speed makes it an ideal choice for caching frequently accessed data, reducing database load, and improving overall application performance.
Data Persistence: Redis offers the option to persist data to disk, ensuring that cached data is not lost in case of system failures or restarts. This combination of in-memory speed and data durability makes Redis suitable for use cases where data integrity is crucial.
Automatic Expiration: Redis allows you to set expiration times for cached data. This feature is invaluable for managing cache freshness and ensuring that you don’t serve stale data to your users.
Why we choose PostgresSQL: As we are using for storing the tokens structured database will work. MySQL will also suffice our requirement. But when we are designing enterprise Postgres is best choice. 
Both MySQL and PostgreSQL support replication. PostgreSQL offers synchronous replication, which means that it has two databases running simultaneously, and the primary database is synced with the duplicate database.
PostgreSQL is regarded as a highly extensible tool since it supports various advanced data types that one can’t find in MySQL.
Why we choose Cassandra: Apache Cassandra: Cassandra is a highly scalable and distributed database that can handle large amounts of data and high write and read throughput. It is suitable for real-time analytics and time-series data. 
Single Point of Failure:  Designs that have a single point of failure cannot be considered good designs.

Databases: To avoid single point of failure we will have replica of databases. Primary and replicas will be there, when primary went down, one of replica will act as primary.
Application Servers: We will multiple backup instances to avoid single point of failures.
Optimize Design:

1) We can have multiple MongoDB instances which act as replicas, and we will allocate some replicas for only read operation and other write operation that way we can have better performance. 

2) Further optimize by using Database Sharding 

